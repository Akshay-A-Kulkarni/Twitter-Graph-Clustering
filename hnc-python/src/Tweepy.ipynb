{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/gk/Desktop/Northeastern/MSDS/DS5230_Unsupervised_Machine_Learning/Project/Twitter-Network-Analysis/Notebooks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler('4CmtKtsKT0gzw3iuSJB8LN9nV', 'xDP2YlcAyRkC4jhyshM3q1UHN9bp3AYe2QGvyxtHszmBdqclsM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth.set_access_token('65785693-zUuHedvCJc1xIBiZiOfxvdBKk211hZpvRR6XLyh1r', '98H4uN9y4HEsldiyJzCfejUUdQqJxC811c2RCxxnmrzuv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashtag Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find and Filter tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = \"#COVID19\"\n",
    "date_since = \"2020-03-11\"\n",
    "num_items = 1000\n",
    "\n",
    "new_search = search_words + \" -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "              q=new_search,\n",
    "              lang=\"en\",\n",
    "              since=date_since).items(num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get hashtags into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108.32331109046936"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "hash_tags = [[tweet.id, tweet.entities['hashtags']] for tweet in tweets if tweet.entities['hashtags'] != []]\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for T in hash_tags:\n",
    "    for d in T[1]:\n",
    "        result.append([T[0], d[\"text\"]])\n",
    "\n",
    "result_df = pd.DataFrame(data=result, columns=['tweet_id','hashtag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a collection of tweets with a minimum number of hashtags and join with the initial results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_tweets = result_df.groupby('tweet_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets = covid_tweets[covid_tweets['hashtag'] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_results = pd.merge(result_df, good_tweets, on='tweet_id', how='outer').dropna()\n",
    "good_results = good_results[good_results['hashtag_x'] != search_words.replace(\"#\",\"\")]\n",
    "good_results = good_results[good_results['hashtag_x'] != \"COVID\"]\n",
    "\n",
    "good_results = good_results[(~good_results['hashtag_x'].str.contains(\"COVID\"))\\\n",
    "                            & (~good_results['hashtag_x'].str.contains(\"covid\"))\\\n",
    "                           & (~good_results['hashtag_x'].str.contains(\"Covid\"))\\\n",
    "                           &(~good_results['hashtag_x'].str.contains(\"CORONA\"))\\\n",
    "                           &(~good_results['hashtag_x'].str.contains(\"corona\"))\\\n",
    "                           &(~good_results['hashtag_x'].str.contains(\"Corona\"))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id     162\n",
       "hashtag_x    356\n",
       "hashtag_y      9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_results.nunique() #hashtag_x is unique hashtags, hashtag_y is unique counts of hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = good_results.groupby(['tweet_id','hashtag_x']).size().reset_index().rename(columns={0:'count'})\n",
    "#test[test['count'] > 1]\n",
    "\n",
    "good_results_unique = good_results.drop_duplicates(['tweet_id','hashtag_x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_results_unique.to_csv(r'/Users/gk/Desktop/Northeastern/MSDS/DS5230_Unsupervised_Machine_Learning/Project/COVID19_hashtags_TEST.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweet and User attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet.text\n",
    "#tweet.user.friends_count\n",
    "\n",
    "#attributes = [[tweet.user.screen_name, tweet.user.friends_count, tweet.text] for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet_text = pd.DataFrame(data=attributes, columns=['user', \"friends_count\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet_text['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix messed up hashtag_y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_hashtag_y = pd.read_csv('/Users/gk/Desktop/Northeastern/MSDS/DS5230_Unsupervised_Machine_Learning/Project/csv_archive/COVID19_hashtags7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_y_df = fix_hashtag_y['tweet_id'].value_counts().to_frame()\n",
    "test = pd.merge(fix_hashtag_y, hashtag_y_df, how='left', left_on=['tweet_id'], right_on=[hashtag_y_df.index])\n",
    "test = test.iloc[: , [1,2,3,5]]\n",
    "test = test.rename(columns={'tweet_id_y': 'hashtag_y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    6008\n",
       "tweet_id_x    2579\n",
       "hashtag_x     3509\n",
       "hashtag_y       11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(r'/Users/gk/Desktop/Northeastern/MSDS/DS5230_Unsupervised_Machine_Learning/Project/csv_archive/COVID19_hashtags7_update.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(txt):\n",
    "    \"\"\"Replace URLs found in a text string with nothing \n",
    "    (i.e. it will remove the URL from the string).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    txt : string\n",
    "        A text string that you want to parse and remove urls.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The same txt string with url's removed.\n",
    "    \"\"\"\n",
    "\n",
    "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet_text['text'] = [remove_url(tweet) for tweet in tweets2[tweets2.columns[2]]]\n",
    "#tweet_text['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = remove_duplicates7.groupby(['tweet_id','hashtag_x']).size().reset_index().rename(columns={0:'count'})\n",
    "#test[test['count'] > 1]\n",
    "\n",
    "#remove_duplicates7 = pd.read_csv(r'/Users/gk/Desktop/test_COVID19_hashtags7.csv')\n",
    "#remove_duplicates7 = remove_duplicates7.drop_duplicates(['tweet_id','hashtag_x'])\n",
    "#remove_duplicates7[[\"tweet_id\"]].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_duplicates7.to_csv(r'/Users/gk/Desktop/COVID19_hashtags7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2130.8475909233093"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "tweet_text = []\n",
    "for tweet_id in good_results_unique['tweet_id'].unique():\n",
    "    try:\n",
    "        text = api.get_status(tweet_id, tweet_mode = 'extended')\n",
    "    except tw.TweepError:\n",
    "        continue\n",
    "    tweet_text.append([tweet_id, text.full_text])\n",
    "    \n",
    "tweet_text_df = pd.DataFrame(data=tweet_text, columns=['tweet_id','text']).drop_duplicates(['text'], keep='first')\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate_latest = tweet_text_df.groupby(['text']).size().reset_index().rename(columns={0:'count'})\n",
    "#duplicate_latest[duplicate_latest['count'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text_df.to_csv(r'/Users/gk/Desktop/COVID19_hashtags7_text_TEST.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_data = pd.read_csv('/Users/gk/Desktop/Northeastern/MSDS/DS5230_Unsupervised_Machine_Learning/Project/twitter-network-graph/Hashtag_Data/COVID19_hashtags5_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_text = text_data.groupby(['tweet_id','text']).size().reset_index().rename(columns={0:'count'})\n",
    "#test_text[test_text['count'] > 1]\n",
    "\n",
    "#error_tweets = text_data[(text_data['text'] == 'Error')]['tweet_id']\n",
    "#text_data[text_data['tweet_id'].isin(error_tweets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicate_text = text_data.groupby(['text']).size().reset_index().rename(columns={0:'count'})\n",
    "#duplicate_text[duplicate_text['count'] > 1]\n",
    "\n",
    "#text_data[text_data['text'].str.contains('#BREAKING Kentucky reports first death due to')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = api.get_user('geoffkorb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HamelHusain\n",
      "NaturelsLit\n",
      "JonnyKimUSA\n",
      "aruneshmathur\n",
      "davidgoggins\n",
      "nickfirchau\n",
      "haxor\n",
      "vboykis\n",
      "NewAmericaPIT\n",
      "hunterwalk\n",
      "ProjectLincoln\n",
      "davidrberke\n",
      "jockowillink\n",
      "soccer_minute\n",
      "AndrewM_Webb\n",
      "matt_levine\n",
      "SolidSoundFest\n",
      "ashk4n\n",
      "lexfridman\n",
      "luis_likes_math\n",
      "random_walker\n",
      "numberphile\n",
      "Kurz_Gesagt\n",
      "justmarkham\n",
      "Artoftheproblem\n",
      "PostalService\n",
      "geoffreyhinton\n",
      "seb_ruder\n",
      "GoogleAI\n",
      "tristanharris\n",
      "3blue1brown\n",
      "AeronautBrewing\n",
      "MultilayerNets\n",
      "fastdotai\n",
      "j6aer\n",
      "SpotifyEng\n",
      "GustavS\n",
      "DebateVis\n",
      "MIT_CSAIL\n",
      "costaleabo\n",
      "waitbutwhy\n",
      "lflockwood\n",
      "erez_kaminski\n",
      "policingproject\n",
      "TheBostonCal\n",
      "lucyparsonslabs\n",
      "jeremyphoward\n",
      "themarkup\n",
      "chipro\n",
      "DanOUrban\n",
      "kdnuggets\n",
      "carvellwallace\n",
      "btenergy\n",
      "indexingai\n",
      "OpenAI\n",
      "math3ma\n",
      "brookLYNevery1\n",
      "olgavitek\n",
      "kuwisdelu\n",
      "stefanjwojcik\n",
      "W4ngatang\n",
      "hugobowne\n",
      "nu4good\n",
      "EveryNoise\n",
      "_brohrer_\n",
      "therriaultphd\n",
      "DevotedHealth\n",
      "StanfordHAI\n",
      "AndrewYNg\n",
      "NU_PolicySchool\n",
      "NUlabTMN\n",
      "AllenDowney\n",
      "drivendataorg\n",
      "albarrentine\n",
      "gourmetboutique\n",
      "nugradunion\n",
      "bibim_box\n",
      "VolunteerSci\n",
      "jovialjoy\n",
      "MforJ\n",
      "rahulbot\n",
      "SCDAONews\n",
      "GoNUmhockey\n",
      "IvyChild\n",
      "CathyClassical\n",
      "DARollins\n",
      "ReeseCommaBill\n",
      "PaulNicklen\n",
      "BARIboston\n",
      "FLIxrisk\n",
      "eji_org\n",
      "SistersUnchaind\n",
      "MassBailFund\n",
      "BlackArrowFC\n",
      "MLSRewind\n",
      "jakeporway\n",
      "criedl\n",
      "michelle_borkin\n",
      "KhouryCollege\n",
      "mentalpod\n",
      "viegasf\n",
      "jjthomaswi\n",
      "becky_boitnott\n",
      "ProtonMail\n",
      "simplystats\n",
      "datascifellows\n",
      "kaggle\n",
      "Data4BlackLives\n",
      "uclbdi\n",
      "jakevdp\n",
      "PreetBharara\n",
      "bostonpython\n",
      "Once_A_Metro\n",
      "hmason\n",
      "RayDalio\n",
      "TheNutmegNews\n",
      "JasonRBNY\n",
      "micahflee\n",
      "yonatanzunger\n",
      "siminnikbinmeyd\n",
      "MarisaHTaylor\n",
      "101_cares\n",
      "HeartbreakRunCo\n",
      "wers889\n",
      "netBlazr\n",
      "tphilipakos\n",
      "BeStrongFirst\n",
      "notsmartblog\n",
      "AbandonedStates\n",
      "UrbanHops\n",
      "MindfulEveryday\n",
      "RBNYOptimist\n",
      "torproject\n",
      "Erowid\n",
      "ByDougMcIntyre\n",
      "jessemarsch\n",
      "Beyond_Shelter\n",
      "stevehoff\n",
      "MAPS\n",
      "artofmanliness\n",
      "EmergencyPuppy\n",
      "TheOffsideRules\n",
      "LurkCyphers\n",
      "longshotpodcast\n",
      "_DamianJames\n",
      "MrTomCowell\n",
      "timtheredmenace\n",
      "nmv4\n",
      "petkemike\n",
      "NotHansBacke\n",
      "khiebert\n",
      "svertelney\n",
      "OptaJack\n",
      "HomebrewTVN\n",
      "MattDoyle76\n",
      "thecomicscomic\n",
      "galifianakisz\n",
      "BrianStraus\n",
      "trublubruin\n",
      "SeeingRedNY\n",
      "EmpireSC\n",
      "TheVipersNest\n",
      "BrentJavan\n",
      "MarkFishkin\n",
      "SteveDavis90\n",
      "JeffreyCarlisle\n",
      "footiebusiness\n",
      "shinguardian\n",
      "Gaetjens\n",
      "ACS\n",
      "dunord\n",
      "susanhan\n",
      "changsterilla\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "generator raised StopIteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-79cb84cbba8f>\u001b[0m in \u001b[0;36mlimit_handled\u001b[0;34m(cursor)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRateLimitError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_cursor\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_tweets\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         data, cursors = self.method(cursor=self.next_cursor,\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-79cb84cbba8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgk_friends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfriend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlimit_handled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfriends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfriend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: generator raised StopIteration"
     ]
    }
   ],
   "source": [
    "def limit_handled(cursor):\n",
    "    while True:\n",
    "        try:\n",
    "            yield cursor.next()\n",
    "        except tw.RateLimitError:\n",
    "            time.sleep(15 * 60)\n",
    "\n",
    "gk_friends = []            \n",
    "            \n",
    "for friend in limit_handled(tw.Cursor(api.friends).items()):\n",
    "    print(friend.screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edgelist (followers followees)\n",
    "#attribute (user attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv and run nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
